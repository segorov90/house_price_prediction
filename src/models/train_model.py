import numpy as np
import pandas as pd
import joblib
import yaml
import os
import logging
from typing import Dict, List, Tuple, Any, Optional
from datetime import datetime
from pathlib import Path

# –ò–º–ø–æ—Ä—Ç –º–æ–¥–µ–ª–µ–π
from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.svm import SVR
from xgboost import XGBRegressor
from sklearn.neighbors import KNeighborsRegressor

# –ò–º–ø–æ—Ä—Ç –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ –æ—Ü–µ–Ω–∫–∏
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.model_selection import cross_val_score, GridSearchCV, RandomizedSearchCV

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class ModelTrainer:
    """
    –ö–ª–∞—Å—Å –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –∏ –æ—Ü–µ–Ω–∫–∏ –º–æ–¥–µ–ª–µ–π –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è
    """

    def __init__(self, config_path: str = "configs/config.yaml"):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ç—Ä–µ–Ω–µ—Ä–∞ –º–æ–¥–µ–ª–µ–π

        Args:
            config_path: –ü—É—Ç—å –∫ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–Ω–æ–º—É —Ñ–∞–π–ª—É
        """
        self.config = self._load_config(config_path)
        self.models = {}
        self.results = {}
        self.best_model = None
        self.best_model_name = None

        # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
        self._create_directories()

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–µ–π
        self._initialize_models()

    def _load_config(self, config_path: str) -> dict:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é"""
        with open(config_path, 'r') as f:
            return yaml.safe_load(f)

    def _create_directories(self):
        """–°–æ–∑–¥–∞–µ—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏"""
        directories = [
            'models/trained',
            'models/optimized',
            'reports/model_results',
            'logs'
        ]

        for directory in directories:
            os.makedirs(directory, exist_ok=True)

    def _initialize_models(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –º–æ–¥–µ–ª–∏ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è"""

        # –ë–∞–∑–æ–≤—ã–µ –º–æ–¥–µ–ª–∏
        self.models = {
            'LinearRegression': {
                'model': LinearRegression(),
                'params': {}
            },
            'Ridge': {
                'model': Ridge(random_state=self.config['model']['random_state']),
                'params': {
                    'alpha': [0.1, 1.0, 10.0, 100.0]
                }
            },
            'Lasso': {
                'model': Lasso(random_state=self.config['model']['random_state']),
                'params': {
                    'alpha': [0.1, 1.0, 10.0]
                }
            },
            'RandomForest': {
                'model': RandomForestRegressor(random_state=self.config['model']['random_state'], n_jobs=-1),
                'params': {
                    'n_estimators': [100, 200],
                    'max_depth': [10, 20, None],
                    'min_samples_split': [2, 5]
                }
            },
            'GradientBoosting': {
                'model': GradientBoostingRegressor(random_state=self.config['model']['random_state']),
                'params': {
                    'n_estimators': [100, 200],
                    'learning_rate': [0.01, 0.1],
                    'max_depth': [3, 5]
                }
            },
            'XGBoost': {
                'model': XGBRegressor(random_state=self.config['model']['random_state'], verbosity=0),
                'params': {
                    'n_estimators': [100, 200],
                    'learning_rate': [0.01, 0.1],
                    'max_depth': [3, 5, 7],
                    'subsample': [0.8, 1.0]
                }
            }
        }

        # –ü—Ä–æ—Å—Ç—ã–µ –º–æ–¥–µ–ª–∏ –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        self.simple_models = {
            'LinearRegression': LinearRegression(),
            'Ridge': Ridge(alpha=1.0, random_state=self.config['model']['random_state']),
            'RandomForest': RandomForestRegressor(
                n_estimators=100,
                random_state=self.config['model']['random_state'],
                n_jobs=-1
            )
        }

    def load_data(self) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:
        """
        –ó–∞–≥—Ä—É–∂–∞–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ

        Returns:
            Tuple: X_train, X_test, y_train, y_test
        """
        try:
            processed_data = joblib.load('data/processed/processed_data.pkl')

            X_train = processed_data['X_train']
            X_test = processed_data['X_test']
            y_train = processed_data['y_train']
            y_test = processed_data['y_test']

            logger.info(f"–î–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã. X_train: {X_train.shape}, X_test: {X_test.shape}")

            # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–º–µ–Ω–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            if os.path.exists('models/feature_names.pkl'):
                feature_info = joblib.load('models/feature_names.pkl')
                self.feature_names = feature_info.get('all_features', [])
                logger.info(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(self.feature_names)} –∏–º–µ–Ω –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")

            return X_train, X_test, y_train, y_test

        except FileNotFoundError:
            logger.error("–û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã. –°–Ω–∞—á–∞–ª–∞ –≤—ã–ø–æ–ª–Ω–∏—Ç–µ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫—É.")
            raise

    def evaluate_model(self, model, X_train: np.ndarray, y_train: np.ndarray,
                       X_test: np.ndarray, y_test: np.ndarray,
                       model_name: str = "Unknown") -> Dict[str, Any]:
        """
        –û—Ü–µ–Ω–∏–≤–∞–µ—Ç –º–æ–¥–µ–ª—å –Ω–∞ train –∏ test –Ω–∞–±–æ—Ä–∞—Ö

        Args:
            model: –û–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å
            X_train, y_train: –¢—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
            X_test, y_test: –¢–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
            model_name: –ò–º—è –º–æ–¥–µ–ª–∏

        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏
        """
        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        y_train_pred = model.predict(X_train)
        y_test_pred = model.predict(X_test)

        # –û–±—Ä–∞—Ç–Ω–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –∏–∑ –ª–æ–≥–∞—Ä–∏—Ñ–º–∞ (–µ—Å–ª–∏ –ø—Ä–∏–º–µ–Ω—è–ª–æ—Å—å)
        if np.all(y_train < 20):  # –≠–≤—Ä–∏—Å—Ç–∏–∫–∞: –µ—Å–ª–∏ –∑–Ω–∞—á–µ–Ω–∏—è –º–∞–ª–µ–Ω—å–∫–∏–µ, –≤–µ—Ä–æ—è—Ç–Ω–æ —ç—Ç–æ –ª–æ–≥–∞—Ä–∏—Ñ–º
            y_train_exp = np.expm1(y_train)
            y_test_exp = np.expm1(y_test)
            y_train_pred_exp = np.expm1(y_train_pred)
            y_test_pred_exp = np.expm1(y_test_pred)
        else:
            y_train_exp = y_train
            y_test_exp = y_test
            y_train_pred_exp = y_train_pred
            y_test_pred_exp = y_test_pred

        # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫
        metrics = {
            'model_name': model_name,
            'train_r2': r2_score(y_train, y_train_pred),
            'test_r2': r2_score(y_test, y_test_pred),
            'train_mae': mean_absolute_error(y_train_exp, y_train_pred_exp),
            'test_mae': mean_absolute_error(y_test_exp, y_test_pred_exp),
            'train_rmse': np.sqrt(mean_squared_error(y_train_exp, y_train_pred_exp)),
            'test_rmse': np.sqrt(mean_squared_error(y_test_exp, y_test_pred_exp)),
            'train_mape': self._mean_absolute_percentage_error(y_train_exp, y_train_pred_exp),
            'test_mape': self._mean_absolute_percentage_error(y_test_exp, y_test_pred_exp)
        }

        # –ö—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è
        try:
            cv_scores = cross_val_score(model, X_train, y_train,
                                        cv=5, scoring='r2', n_jobs=-1)
            metrics['cv_r2_mean'] = cv_scores.mean()
            metrics['cv_r2_std'] = cv_scores.std()
        except Exception as e:
            logger.warning(f"–ö—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è –Ω–µ —É–¥–∞–ª–∞—Å—å –¥–ª—è {model_name}: {e}")
            metrics['cv_r2_mean'] = None
            metrics['cv_r2_std'] = None

        return metrics

    def _mean_absolute_percentage_error(self, y_true: np.ndarray, y_pred: np.ndarray) -> float:
        """
        –í—ã—á–∏—Å–ª—è–µ—Ç —Å—Ä–µ–¥–Ω—é—é –∞–±—Å–æ–ª—é—Ç–Ω—É—é –ø—Ä–æ—Ü–µ–Ω—Ç–Ω—É—é –æ—à–∏–±–∫—É

        Args:
            y_true: –ò—Å—Ç–∏–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
            y_pred: –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è

        Returns:
            MAPE –≤ –ø—Ä–æ—Ü–µ–Ω—Ç–∞—Ö
        """
        # –ò–∑–±–µ–≥–∞–µ–º –¥–µ–ª–µ–Ω–∏—è –Ω–∞ –Ω–æ–ª—å
        y_true, y_pred = np.array(y_true), np.array(y_pred)
        mask = y_true != 0
        if np.sum(mask) == 0:
            return 100.0

        return np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100

    def train_models(self, X_train: np.ndarray, y_train: np.ndarray,
                     X_test: np.ndarray, y_test: np.ndarray,
                     mode: str = 'simple') -> Dict[str, Dict]:
        """
        –û–±—É—á–∞–µ—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–æ–¥–µ–ª–µ–π –∏ –æ—Ü–µ–Ω–∏–≤–∞–µ—Ç –∏—Ö

        Args:
            X_train, y_train: –¢—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
            X_test, y_test: –¢–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
            mode: –†–µ–∂–∏–º –æ–±—É—á–µ–Ω–∏—è ('simple', 'full', 'optimize')

        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π
        """
        logger.info(f"–ù–∞—á–∞–ª–æ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π –≤ —Ä–µ–∂–∏–º–µ '{mode}'")
        self.results = {}

        if mode == 'simple':
            models_to_train = self.simple_models
        else:
            models_to_train = {name: data['model'] for name, data in self.models.items()}

        for model_name, model in models_to_train.items():
            try:
                logger.info(f"–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏: {model_name}")

                # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
                start_time = datetime.now()
                model.fit(X_train, y_train)
                training_time = (datetime.now() - start_time).total_seconds()

                # –û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏
                metrics = self.evaluate_model(model, X_train, y_train, X_test, y_test, model_name)
                metrics['training_time'] = training_time

                # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
                self._save_model(model, model_name)

                # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
                self.results[model_name] = {
                    'model': model,
                    'metrics': metrics
                }

                logger.info(f"  {model_name}: Test R¬≤ = {metrics['test_r2']:.4f}, "
                            f"Test RMSE = {metrics['test_rmse']:.2f}")

            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ {model_name}: {e}")

        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏ –ø–æ R¬≤ –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        self._select_best_model()

        return self.results

    def optimize_model(self, model_name: str, X_train: np.ndarray, y_train: np.ndarray) -> Any:
        """
        –û–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ—Ç –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏ —Å –ø–æ–º–æ—â—å—é GridSearch

        Args:
            model_name: –ò–º—è –º–æ–¥–µ–ª–∏ –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
            X_train, y_train: –¢—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ

        Returns:
            –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å
        """
        if model_name not in self.models:
            logger.error(f"–ú–æ–¥–µ–ª—å {model_name} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ —Å–ø–∏—Å–∫–µ –º–æ–¥–µ–ª–µ–π")
            return None

        logger.info(f"–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –¥–ª—è {model_name}")

        model_config = self.models[model_name]
        model = model_config['model']
        params = model_config['params']

        # –ò—Å–ø–æ–ª—å–∑—É–µ–º RandomizedSearchCV –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞
        search = RandomizedSearchCV(
            estimator=model,
            param_distributions=params,
            n_iter=10,  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏—Ç–µ—Ä–∞—Ü–∏–π
            cv=3,
            scoring='r2',
            n_jobs=-1,
            random_state=self.config['model']['random_state'],
            verbose=1
        )

        search.fit(X_train, y_train)

        logger.info(f"–õ—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è {model_name}: {search.best_params_}")
        logger.info(f"–õ—É—á—à–∏–π score: {search.best_score_:.4f}")

        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
        best_model = search.best_estimator_
        self._save_model(best_model, f"{model_name}_optimized")

        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ–± –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
        optimization_info = {
            'model_name': model_name,
            'best_params': search.best_params_,
            'best_score': search.best_score_,
            'cv_results': search.cv_results_
        }

        joblib.dump(optimization_info, f'models/optimized/{model_name}_optimization.pkl')

        return best_model

    def _select_best_model(self):
        """–í—ã–±–∏—Ä–∞–µ—Ç –ª—É—á—à—É—é –º–æ–¥–µ–ª—å –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–µ—Å—Ç–æ–≤–æ–≥–æ R¬≤"""
        if not self.results:
            return

        best_model_name = None
        best_test_r2 = -float('inf')

        for model_name, result in self.results.items():
            test_r2 = result['metrics']['test_r2']
            if test_r2 > best_test_r2:
                best_test_r2 = test_r2
                best_model_name = model_name

        self.best_model_name = best_model_name
        self.best_model = self.results[best_model_name]['model']

        logger.info(f"–õ—É—á—à–∞—è –º–æ–¥–µ–ª—å: {best_model_name} —Å R¬≤ = {best_test_r2:.4f}")

    def _save_model(self, model, model_name: str):
        """
        –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –º–æ–¥–µ–ª—å –≤ —Ñ–∞–π–ª

        Args:
            model: –ú–æ–¥–µ–ª—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
            model_name: –ò–º—è –º–æ–¥–µ–ª–∏
        """
        # –û—á–∏—â–∞–µ–º –∏–º—è —Ñ–∞–π–ª–∞ –æ—Ç –Ω–µ–¥–æ–ø—É—Å—Ç–∏–º—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤
        safe_name = "".join(c for c in model_name if c.isalnum() or c in (' ', '_')).rstrip()
        filename = f"models/trained/{safe_name}.pkl"

        joblib.dump(model, filename)
        logger.debug(f"–ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {filename}")

    def save_results(self):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±—É—á–µ–Ω–∏—è –≤ —Ñ–∞–π–ª—ã"""
        if not self.results:
            logger.warning("–ù–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è")
            return

        # –°–æ–∑–¥–∞–µ–º DataFrame —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏
        metrics_list = []
        for model_name, result in self.results.items():
            metrics = result['metrics'].copy()
            metrics_list.append(metrics)

        metrics_df = pd.DataFrame(metrics_list)

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ CSV
        csv_path = 'reports/model_results/metrics_comparison.csv'
        metrics_df.to_csv(csv_path, index=False, encoding='utf-8')

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ Excel —Å —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ–º
        excel_path = 'reports/model_results/metrics_comparison.xlsx'
        with pd.ExcelWriter(excel_path, engine='openpyxl') as writer:
            metrics_df.to_excel(writer, sheet_name='Metrics', index=False)

            # –ü–æ–ª—É—á–∞–µ–º –æ–±—ä–µ–∫—Ç workbook –¥–ª—è —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
            workbook = writer.book
            worksheet = writer.sheets['Metrics']

            # –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤
            for col in range(len(metrics_df.columns)):
                column_letter = chr(65 + col)  # A, B, C, ...
                worksheet.column_dimensions[column_letter].width = 15

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–≤–æ–¥–Ω—ã–π –æ—Ç—á–µ—Ç
        self._create_summary_report(metrics_df)

        logger.info(f"–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {csv_path} –∏ {excel_path}")

    def _create_summary_report(self, metrics_df: pd.DataFrame):
        """–°–æ–∑–¥–∞–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç—á–µ—Ç —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏"""
        report_lines = []
        report_lines.append("=" * 80)
        report_lines.append("–û–¢–ß–ï–¢ –û–ë –û–ë–£–ß–ï–ù–ò–ò –ú–û–î–ï–õ–ï–ô")
        report_lines.append(f"–î–∞—Ç–∞: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        report_lines.append("=" * 80)

        if self.best_model_name:
            report_lines.append(f"\n–õ–£–ß–®–ê–Ø –ú–û–î–ï–õ–¨: {self.best_model_name}")
            best_metrics = metrics_df[metrics_df['model_name'] == self.best_model_name].iloc[0]

            report_lines.append("\n–ú–µ—Ç—Ä–∏–∫–∏ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏:")
            report_lines.append(f"  R¬≤ –Ω–∞ —Ç–µ—Å—Ç–µ: {best_metrics['test_r2']:.4f}")
            report_lines.append(f"  RMSE –Ω–∞ —Ç–µ—Å—Ç–µ: {best_metrics['test_rmse']:.2f}")
            report_lines.append(f"  MAE –Ω–∞ —Ç–µ—Å—Ç–µ: {best_metrics['test_mae']:.2f}")
            report_lines.append(f"  MAPE –Ω–∞ —Ç–µ—Å—Ç–µ: {best_metrics['test_mape']:.2f}%")
            if pd.notna(best_metrics.get('cv_r2_mean')):
                report_lines.append(
                    f"  –ö—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è R¬≤: {best_metrics['cv_r2_mean']:.4f} (¬±{best_metrics['cv_r2_std']:.4f})")

        report_lines.append("\n" + "=" * 80)
        report_lines.append("–°–†–ê–í–ù–ï–ù–ò–ï –í–°–ï–• –ú–û–î–ï–õ–ï–ô")
        report_lines.append("=" * 80)

        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ test_r2
        sorted_df = metrics_df.sort_values('test_r2', ascending=False)

        for _, row in sorted_df.iterrows():
            report_lines.append(f"\n{row['model_name']}:")
            report_lines.append(f"  Test R¬≤: {row['test_r2']:.4f}")
            report_lines.append(f"  Test RMSE: {row['test_rmse']:.2f}")
            report_lines.append(f"  –í—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è: {row.get('training_time', 'N/A'):.2f} —Å–µ–∫")

        report_lines.append("\n" + "=" * 80)
        report_lines.append("–†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò")
        report_lines.append("=" * 80)

        # –ê–Ω–∞–ª–∏–∑ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è
        overfitting_models = []
        for _, row in metrics_df.iterrows():
            diff = row['train_r2'] - row['test_r2']
            if diff > 0.15:  # –ï—Å–ª–∏ —Ä–∞–∑–Ω–∏—Ü–∞ –±–æ–ª—å—à–µ 15%
                overfitting_models.append((row['model_name'], diff))

        if overfitting_models:
            report_lines.append("\n‚ö† –í–û–ó–ú–û–ñ–ù–û–ï –ü–ï–†–ï–û–ë–£–ß–ï–ù–ò–ï:")
            for model_name, diff in overfitting_models:
                report_lines.append(f"  - {model_name}: —Ä–∞–∑–Ω–∏—Ü–∞ train/test R¬≤ = {diff:.3f}")
            report_lines.append("  –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è: –¥–æ–±–∞–≤–∏—Ç—å —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—é –∏–ª–∏ —É–º–µ–Ω—å—à–∏—Ç—å —Å–ª–æ–∂–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏")
        else:
            report_lines.append("\n‚úì –ü—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å–µ—Ä—å–µ–∑–Ω–æ–≥–æ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ")

        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —É–ª—É—á—à–µ–Ω–∏—é
        report_lines.append("\nüìà –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –ü–û –£–õ–£–ß–®–ï–ù–ò–Æ:")
        report_lines.append("  1. –°–æ–±—Ä–∞—Ç—å –±–æ–ª—å—à–µ –¥–∞–Ω–Ω—ã—Ö")
        report_lines.append("  2. –î–æ–±–∞–≤–∏—Ç—å –Ω–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (feature engineering)")
        report_lines.append("  3. –ü–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –∞–Ω—Å–∞–º–±–ª–µ–≤—ã–µ –º–µ—Ç–æ–¥—ã (Stacking, Voting)")
        report_lines.append("  4. –ë–æ–ª–µ–µ –≥–ª—É–±–æ–∫–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤")

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç—á–µ—Ç
        report_path = 'reports/model_results/training_summary.txt'
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write('\n'.join(report_lines))

        # –í—ã–≤–æ–¥–∏–º –æ—Ç—á–µ—Ç –≤ –∫–æ–Ω—Å–æ–ª—å
        print('\n'.join(report_lines))
        logger.info(f"–°–≤–æ–¥–Ω—ã–π –æ—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ {report_path}")


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π"""
    logger.info("–ó–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π...")

    try:
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ç—Ä–µ–Ω–µ—Ä–∞
        trainer = ModelTrainer()

        # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        X_train, X_test, y_train, y_test = trainer.load_data()

        # –ë—ã—Å—Ç—Ä–æ–µ –æ–±—É—á–µ–Ω–∏–µ –ø—Ä–æ—Å—Ç—ã—Ö –º–æ–¥–µ–ª–µ–π
        logger.info("\n1. –ë—ã—Å—Ç—Ä–æ–µ –æ–±—É—á–µ–Ω–∏–µ –±–∞–∑–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π...")
        results = trainer.train_models(X_train, y_train, X_test, y_test, mode='simple')

        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        trainer.save_results()

        # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏ (–µ—Å–ª–∏ –Ω—É–∂–Ω–æ)
        logger.info("\n2. –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏...")
        if trainer.best_model_name:
            best_model_name = trainer.best_model_name
            if best_model_name in trainer.models:  # –ï—Å–ª–∏ –µ—Å—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
                optimized_model = trainer.optimize_model(best_model_name, X_train, y_train)

                # –û—Ü–µ–Ω–∫–∞ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
                if optimized_model:
                    optimized_metrics = trainer.evaluate_model(
                        optimized_model, X_train, y_train, X_test, y_test,
                        f"{best_model_name}_optimized"
                    )

                    logger.info(f"\n–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ {best_model_name}:")
                    logger.info(f"  Test R¬≤: {optimized_metrics['test_r2']:.4f}")
                    logger.info(f"  Test RMSE: {optimized_metrics['test_rmse']:.2f}")

        logger.info("\n–û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ —É—Å–ø–µ—à–Ω–æ!")

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ –º–æ–¥–µ–ª–µ–π: {e}")
        raise


if __name__ == "__main__":
    main()