import numpy as np
import pandas as pd
import joblib
import yaml
import logging
from typing import Dict, List, Any, Optional, Union
from pathlib import Path
import sys

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class HousePricePredictor:
    """
    –ö–ª–∞—Å—Å –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Ü–µ–Ω –Ω–∞ –¥–æ–º–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
    """

    def __init__(self, model_path: Optional[str] = None):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–µ–¥–∏–∫—Ç–æ—Ä–∞

        Args:
            model_path: –ü—É—Ç—å –∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏. –ï—Å–ª–∏ None, –∑–∞–≥—Ä—É–∂–∞–µ—Ç –ª—É—á—à—É—é –º–æ–¥–µ–ª—å.
        """
        self.model = None
        self.preprocessor = None
        self.feature_names = None
        self.config = None

        # –ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        self._load_config()

        # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –∏ –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞
        self._load_artifacts(model_path)

        logger.info("–ü—Ä–µ–¥–∏–∫—Ç–æ—Ä –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")

    def _load_config(self):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é"""
        try:
            with open('configs/config.yaml', 'r') as f:
                self.config = yaml.safe_load(f)
        except FileNotFoundError:
            logger.warning("–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–Ω—ã–π —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é")
            self.config = {
                'features': {
                    'numeric_features': [],
                    'categorical_features': []
                }
            }

    def _load_artifacts(self, model_path: Optional[str] = None):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –º–æ–¥–µ–ª—å –∏ –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä"""
        try:
            # –ó–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞
            preprocessor_path = 'models/preprocessor.pkl'
            if Path(preprocessor_path).exists():
                self.preprocessor = joblib.load(preprocessor_path)
                logger.info("–ü—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä –∑–∞–≥—Ä—É–∂–µ–Ω")
            else:
                logger.error("–ü—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä –Ω–µ –Ω–∞–π–¥–µ–Ω")

            # –ó–∞–≥—Ä—É–∑–∫–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –ø—Ä–∏–∑–Ω–∞–∫–∞—Ö
            feature_info_path = 'models/feature_names.pkl'
            if Path(feature_info_path).exists():
                feature_info = joblib.load(feature_info_path)
                self.feature_names = feature_info.get('all_features', [])
                logger.info(f"–ó–∞–≥—Ä—É–∂–µ–Ω—ã –∏–º–µ–Ω–∞ {len(self.feature_names)} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")

            # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
            if model_path and Path(model_path).exists():
                self.model = joblib.load(model_path)
                logger.info(f"–ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∏–∑ {model_path}")
            else:
                # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
                self._load_best_model()

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤: {e}")
            raise

    def _load_best_model(self):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –ª—É—á—à—É—é –º–æ–¥–µ–ª—å –Ω–∞ –æ—Å–Ω–æ–≤–µ –º–µ—Ç—Ä–∏–∫"""
        try:
            # –ß–∏—Ç–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
            metrics_path = 'reports/model_results/metrics_comparison.csv'
            if Path(metrics_path).exists():
                metrics_df = pd.read_csv(metrics_path)
                if not metrics_df.empty:
                    # –ù–∞—Ö–æ–¥–∏–º –º–æ–¥–µ–ª—å —Å –ª—É—á—à–∏–º R¬≤ –Ω–∞ —Ç–µ—Å—Ç–µ
                    best_idx = metrics_df['test_r2'].idxmax()
                    best_model_name = metrics_df.loc[best_idx, 'model_name']

                    # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
                    safe_name = "".join(c for c in best_model_name if c.isalnum() or c in (' ', '_')).rstrip()
                    model_path = f"models/trained/{safe_name}.pkl"

                    if Path(model_path).exists():
                        self.model = joblib.load(model_path)
                        logger.info(f"–ó–∞–≥—Ä—É–∂–µ–Ω–∞ –ª—É—á—à–∞—è –º–æ–¥–µ–ª—å: {best_model_name}")
                        return

            # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ –ª—É—á—à—É—é –º–æ–¥–µ–ª—å, –ø—Ä–æ–±—É–µ–º –∑–∞–≥—Ä—É–∑–∏—Ç—å –ø–µ—Ä–≤—É—é –¥–æ—Å—Ç—É–ø–Ω—É—é
            models_dir = Path('models/trained')
            if models_dir.exists():
                model_files = list(models_dir.glob('*.pkl'))
                if model_files:
                    self.model = joblib.load(model_files[0])
                    logger.info(f"–ó–∞–≥—Ä—É–∂–µ–Ω–∞ –º–æ–¥–µ–ª—å: {model_files[0].name}")
                else:
                    raise FileNotFoundError("–ù–µ—Ç –æ–±—É—á–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –≤ –ø–∞–ø–∫–µ models/trained/")
            else:
                raise FileNotFoundError("–ü–∞–ø–∫–∞ —Å –º–æ–¥–µ–ª—è–º–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏: {e}")
            raise

    def preprocess_input(self, input_data: Union[pd.DataFrame, Dict]) -> np.ndarray:
        """
        –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö

        Args:
            input_data: –í—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –≤ –≤–∏–¥–µ DataFrame –∏–ª–∏ —Å–ª–æ–≤–∞—Ä—è

        Returns:
            –û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –≤ –≤–∏–¥–µ numpy array
        """
        try:
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º —Å–ª–æ–≤–∞—Ä—å –≤ DataFrame
            if isinstance(input_data, dict):
                # –ï—Å–ª–∏ —ç—Ç–æ –æ–¥–∏–Ω –æ–±—Ä–∞–∑–µ—Ü
                if all(isinstance(v, (int, float)) for v in input_data.values()):
                    input_df = pd.DataFrame([input_data])
                else:
                    input_df = pd.DataFrame(input_data)
            else:
                input_df = input_data.copy()

            logger.debug(f"–í—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ: {input_df.shape}")

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –≤—Å–µ—Ö –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            expected_features = set(self.config['features']['numeric_features'] +
                                    self.config['features']['categorical_features'])
            missing_features = expected_features - set(input_df.columns)

            if missing_features:
                logger.warning(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –ø—Ä–∏–∑–Ω–∞–∫–∏: {missing_features}")
                # –î–æ–±–∞–≤–ª—è–µ–º –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ —Å–æ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
                for feature in missing_features:
                    if feature in self.config['features']['numeric_features']:
                        input_df[feature] = 0.0
                    else:
                        input_df[feature] = 'missing'

            # –°–æ–∑–¥–∞–µ–º —Ç–µ –∂–µ –ø—Ä–∏–∑–Ω–∞–∫–∏, —á—Ç–æ –∏ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏
            input_df = self._create_features(input_df)

            # –ü—Ä–∏–º–µ–Ω—è–µ–º –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä
            if self.preprocessor:
                processed_data = self.preprocessor.transform(input_df)
                logger.debug(f"–î–∞–Ω–Ω—ã–µ –ø–æ—Å–ª–µ –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞: {processed_data.shape}")
                return processed_data
            else:
                return input_df.values

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–µ –¥–∞–Ω–Ω—ã—Ö: {e}")
            raise

    def _create_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        –°–æ–∑–¥–∞–µ—Ç —Ç–µ –∂–µ –ø—Ä–∏–∑–Ω–∞–∫–∏, —á—Ç–æ –∏ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏

        Args:
            df: DataFrame —Å –∏—Å—Ö–æ–¥–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏

        Returns:
            DataFrame —Å —Å–æ–∑–¥–∞–Ω–Ω—ã–º–∏ –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏
        """
        df_processed = df.copy()

        # –°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (–¥–æ–ª–∂–Ω–æ —Å–æ–≤–ø–∞–¥–∞—Ç—å —Å –æ–±—É—á–µ–Ω–∏–µ–º)
        if all(col in df.columns for col in ['sqft_living', 'sqft_basement']):
            df_processed['total_sqft'] = df_processed['sqft_living'] + df_processed['sqft_basement']

        if all(col in df.columns for col in ['sqft_living', 'sqft_lot']):
            df_processed['living_to_lot_ratio'] = df_processed['sqft_living'] / df_processed['sqft_lot']

        if all(col in df.columns for col in ['bedrooms', 'floors']):
            df_processed['bedrooms_per_floor'] = df_processed['bedrooms'] / df_processed['floors']
            df_processed['bedrooms_per_floor'] = df_processed['bedrooms_per_floor'].replace([np.inf, -np.inf], 0)

        if 'yr_built' in df.columns:
            df_processed['house_age'] = 2024 - df_processed['yr_built']

        if all(col in df.columns for col in ['grade', 'condition']):
            df_processed['grade_condition'] = df_processed['grade'] * df_processed['condition']

        if all(col in df.columns for col in ['sqft_living', 'bathrooms']):
            df_processed['sqft_per_bathroom'] = df_processed['sqft_living'] / (df_processed['bathrooms'] + 0.001)
            df_processed['sqft_per_bathroom'] = df_processed['sqft_per_bathroom'].replace([np.inf, -np.inf], np.nan)

        return df_processed

    def predict(self, input_data: Union[pd.DataFrame, Dict],
                return_confidence: bool = False) -> Union[float, Dict]:
        """
        –ü—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç —Ü–µ–Ω—É –¥–æ–º–∞

        Args:
            input_data: –í—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
            return_confidence: –í–æ–∑–≤—Ä–∞—â–∞—Ç—å –ª–∏ –¥–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–π –∏–Ω—Ç–µ—Ä–≤–∞–ª

        Returns:
            –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–∞—è —Ü–µ–Ω–∞ –∏–ª–∏ —Å–ª–æ–≤–∞—Ä—å —Å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ–º –∏ –¥–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–º –∏–Ω—Ç–µ—Ä–≤–∞–ª–æ–º
        """
        try:
            # –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö
            processed_data = self.preprocess_input(input_data)

            # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
            prediction_log = self.model.predict(processed_data)

            # –û–±—Ä–∞—Ç–Ω–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –∏–∑ –ª–æ–≥–∞—Ä–∏—Ñ–º–∞
            prediction = np.expm1(prediction_log)

            # –û–∫—Ä—É–≥–ª–µ–Ω–∏–µ –¥–æ 2 –∑–Ω–∞–∫–æ–≤
            prediction = np.round(prediction, 2)

            if return_confidence:
                # –í—ã—á–∏—Å–ª—è–µ–º –¥–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–π –∏–Ω—Ç–µ—Ä–≤–∞–ª (–ø—Ä–æ—Å—Ç–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞)
                # –í —Ä–µ–∞–ª—å–Ω–æ–º –ø—Ä–æ–µ–∫—Ç–µ –ª—É—á—à–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å Quantile Regression –∏–ª–∏ Bayesian –º–µ—Ç–æ–¥—ã
                confidence_interval = self._calculate_confidence_interval(prediction_log)
                confidence_interval = np.expm1(confidence_interval)

                return {
                    'prediction': prediction[0] if len(prediction) == 1 else prediction,
                    'confidence_interval': confidence_interval,
                    'prediction_log': prediction_log[0] if len(prediction_log) == 1 else prediction_log
                }
            else:
                return prediction[0] if len(prediction) == 1 else prediction

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–∏: {e}")
            raise

    def _calculate_confidence_interval(self, prediction_log: np.ndarray,
                                       confidence_level: float = 0.95) -> np.ndarray:
        """
        –í—ã—á–∏—Å–ª—è–µ—Ç –¥–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–π –∏–Ω—Ç–µ—Ä–≤–∞–ª –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è

        Args:
            prediction_log: –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –≤ –ª–æ–≥–∞—Ä–∏—Ñ–º–∏—á–µ—Å–∫–æ–π —à–∫–∞–ª–µ
            confidence_level: –£—Ä–æ–≤–µ–Ω—å –¥–æ–≤–µ—Ä–∏—è

        Returns:
            –î–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–π –∏–Ω—Ç–µ—Ä–≤–∞–ª [–Ω–∏–∂–Ω—è—è_–≥—Ä–∞–Ω–∏—Ü–∞, –≤–µ—Ä—Ö–Ω—è—è_–≥—Ä–∞–Ω–∏—Ü–∞]
        """
        # –ü—Ä–æ—Å—Ç–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞: ¬±20% –æ—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –≤ –ª–æ–≥–∞—Ä–∏—Ñ–º–∏—á–µ—Å–∫–æ–π —à–∫–∞–ª–µ
        # –í —Ä–µ–∞–ª—å–Ω–æ–º –ø—Ä–æ–µ–∫—Ç–µ –Ω—É–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –±–æ–ª–µ–µ —Å–ª–æ–∂–Ω—ã–µ –º–µ—Ç–æ–¥—ã
        margin = 0.2

        lower_bound = prediction_log * (1 - margin)
        upper_bound = prediction_log * (1 + margin)

        return np.column_stack([lower_bound, upper_bound])

    def batch_predict(self, input_data: pd.DataFrame) -> pd.DataFrame:
        """
        –ü–∞–∫–µ—Ç–Ω–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –¥–ª—è –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –¥–æ–º–æ–≤

        Args:
            input_data: DataFrame —Å –¥–∞–Ω–Ω—ã–º–∏ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –¥–æ–º–æ–≤

        Returns:
            DataFrame —Å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è–º–∏
        """
        try:
            predictions = self.predict(input_data, return_confidence=False)

            result_df = input_data.copy()
            result_df['predicted_price'] = predictions
            result_df['prediction_timestamp'] = pd.Timestamp.now()

            return result_df

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞–∫–µ—Ç–Ω–æ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–∏: {e}")
            raise

    def get_model_info(self) -> Dict:
        """
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –º–æ–¥–µ–ª–∏

        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ –º–æ–¥–µ–ª–∏
        """
        info = {
            'model_type': type(self.model).__name__ if self.model else None,
            'features_count': len(self.feature_names) if self.feature_names else 0,
            'preprocessor_loaded': self.preprocessor is not None,
            'config_features': {
                'numeric': self.config['features']['numeric_features'],
                'categorical': self.config['features']['categorical_features']
            }
        }

        if self.model:
            # –î–æ–±–∞–≤–ª—è–µ–º —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –º–æ–¥–µ–ª–∏
            if hasattr(self.model, 'n_estimators'):
                info['n_estimators'] = self.model.n_estimators
            if hasattr(self.model, 'feature_importances_'):
                info['has_feature_importances'] = True

        return info


def main():
    """–ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø—Ä–µ–¥–∏–∫—Ç–æ—Ä–∞"""
    import json

    print("=" * 60)
    print("–¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ú–û–î–ï–õ–ò –ü–†–ï–î–°–ö–ê–ó–ê–ù–ò–Ø –¶–ï–ù –ù–ê –î–û–ú–ê")
    print("=" * 60)

    try:
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–µ–¥–∏–∫—Ç–æ—Ä–∞
        predictor = HousePricePredictor()

        # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏
        model_info = predictor.get_model_info()
        print("\nüìä –ò–ù–§–û–†–ú–ê–¶–ò–Ø –û –ú–û–î–ï–õ–ò:")
        print(f"  –¢–∏–ø –º–æ–¥–µ–ª–∏: {model_info['model_type']}")
        print(f"  –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {model_info['features_count']}")
        print(f"  –ß–∏—Å–ª–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏: {len(model_info['config_features']['numeric'])}")
        print(f"  –ö–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏: {len(model_info['config_features']['categorical'])}")

        # –¢–µ—Å—Ç–æ–≤—ã–π –ø—Ä–∏–º–µ—Ä
        print("\nüß™ –¢–ï–°–¢–û–í–û–ï –ü–†–ï–î–°–ö–ê–ó–ê–ù–ò–ï:")

        test_house = {
            'sqft_living': 2000,
            'sqft_lot': 8000,
            'sqft_above': 1500,
            'sqft_basement': 500,
            'bedrooms': 3,
            'bathrooms': 2.5,
            'floors': 2,
            'waterfront': 0,
            'view': 3,
            'condition': 5,
            'grade': 8,
            'yr_built': 1995,
            'zipcode': 98115,
            'lat': 47.68,
            'long': -122.29
        }

        print("  –•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –¥–æ–º–∞:")
        for key, value in test_house.items():
            print(f"    {key}: {value}")

        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Å –¥–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–º –∏–Ω—Ç–µ—Ä–≤–∞–ª–æ–º
        result = predictor.predict(test_house, return_confidence=True)

        print(f"\n  üè† –ü–†–ï–î–°–ö–ê–ó–ê–ù–ù–ê–Ø –¶–ï–ù–ê: ${result['prediction']:,.2f}")

        if 'confidence_interval' in result:
            ci = result['confidence_interval'][0]
            print(f"  üìä –î–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–π –∏–Ω—Ç–µ—Ä–≤–∞–ª (95%):")
            print(f"     –ù–∏–∂–Ω—è—è –≥—Ä–∞–Ω–∏—Ü–∞: ${ci[0]:,.2f}")
            print(f"     –í–µ—Ä—Ö–Ω—è—è –≥—Ä–∞–Ω–∏—Ü–∞: ${ci[1]:,.2f}")

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–∏–º–µ—Ä –¥–ª—è API
        example_path = 'api/example_request.json'
        Path('api').mkdir(exist_ok=True)

        example_data = {
            'house_data': test_house,
            'prediction_result': {
                'predicted_price': float(result['prediction']),
                'confidence_interval': result[
                    'confidence_interval'].tolist() if 'confidence_interval' in result else None
            }
        }

        with open(example_path, 'w') as f:
            json.dump(example_data, f, indent=2)

        print(f"\n‚úÖ –ü—Ä–∏–º–µ—Ä –∑–∞–ø—Ä–æ—Å–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ {example_path}")

        # –ü–∞–∫–µ—Ç–Ω–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
        print("\nüì¶ –ü–ê–ö–ï–¢–ù–û–ï –ü–†–ï–î–°–ö–ê–ó–ê–ù–ò–ï:")

        test_houses = pd.DataFrame([test_house, {
            'sqft_living': 3000,
            'sqft_lot': 10000,
            'sqft_above': 2500,
            'sqft_basement': 500,
            'bedrooms': 4,
            'bathrooms': 3.0,
            'floors': 2,
            'waterfront': 1,
            'view': 4,
            'condition': 5,
            'grade': 10,
            'yr_built': 2010,
            'zipcode': 98004,
            'lat': 47.62,
            'long': -122.24
        }])

        batch_results = predictor.batch_predict(test_houses)
        print("  –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–∞–∫–µ—Ç–Ω–æ–≥–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è:")
        print(batch_results[['sqft_living', 'bedrooms', 'bathrooms', 'predicted_price']].to_string(index=False))

    except Exception as e:
        print(f"\n‚ùå –û—à–∏–±–∫–∞: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()