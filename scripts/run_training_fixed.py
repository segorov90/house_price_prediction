
# !/usr/bin/env python


"""
–£–ø—Ä–æ—â–µ–Ω–Ω—ã–π —Å–∫—Ä–∏–ø—Ç –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π.
–ó–∞–ø—É—Å–∫: python scripts/run_training_fixed.py
"""

import os
import sys
import pandas as pd
import numpy as np
from pathlib import Path

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–Ω–µ–≤—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –≤ –ø—É—Ç—å
project_root = Path(__file__).parent.parent
sys.path.append(str(project_root))


def check_and_preprocess_data():
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∏ –ø–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ"""
    print("\n1. –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")

    processed_path = project_root / "data" / "processed" / "house_prices_processed.csv"

    if not processed_path.exists():
        print("   ‚ö† –û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
        print("   –ó–∞–ø—É—Å–∫–∞–µ–º –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫—É...")

        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—ã—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ
            raw_path = project_root / "data" / "raw" / "house_prices.csv"

            if not raw_path.exists():
                print("   ‚ö† –°—ã—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã, —Å–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ...")
                from src.data.make_dataset import create_sample_data
                df_raw = create_sample_data(500)
                raw_path.parent.mkdir(parents=True, exist_ok=True)
                df_raw.to_csv(raw_path, index=False)
                print(f"   ‚úÖ –°–æ–∑–¥–∞–Ω—ã —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ: {raw_path}")
            else:
                df_raw = pd.read_csv(raw_path)
                print(f"   ‚úÖ –°—ã—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã: {df_raw.shape}")

            # –ü—Ä–æ—Å—Ç–∞—è –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞
            print("   üõ† –í—ã–ø–æ–ª–Ω—è–µ–º –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫—É...")

            # –ó–∞–ø–æ–ª–Ω—è–µ–º –ø—Ä–æ–ø—É—Å–∫–∏
            numeric_cols = df_raw.select_dtypes(include=[np.number]).columns
            df_processed = df_raw.copy()
            df_processed[numeric_cols] = df_processed[numeric_cols].fillna(df_processed[numeric_cols].median())

            # –£–¥–∞–ª—è–µ–º –Ω–µ—á–∏—Å–ª–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏
            non_numeric = df_processed.select_dtypes(include=['object']).columns
            if len(non_numeric) > 0:
                df_processed = df_processed.drop(columns=non_numeric)

            # –õ–æ–≥–∞—Ä–∏—Ñ–º–∏—Ä—É–µ–º —Ü–µ–ª–µ–≤—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –µ—Å–ª–∏ –µ—Å—Ç—å
            if 'price' in df_processed.columns:
                # –£–±–µ–¥–∏–º—Å—è —á—Ç–æ –≤—Å–µ —Ü–µ–Ω—ã –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–µ
                min_price = df_processed['price'].min()
                if min_price <= 0:
                    df_processed['price'] = df_processed['price'] - min_price + 1
                df_processed['price_log'] = np.log1p(df_processed['price'])

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º
            processed_path.parent.mkdir(parents=True, exist_ok=True)
            df_processed.to_csv(processed_path, index=False)
            print(f"   ‚úÖ –î–∞–Ω–Ω—ã–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {processed_path}")

            return True

        except Exception as e:
            print(f"   ‚úó –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–µ: {e}")
            return False
    else:
        print(f"   ‚úÖ –î–∞–Ω–Ω—ã–µ –Ω–∞–π–¥–µ–Ω—ã: {processed_path}")
        return True


def load_and_prepare_data():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∏ –ø–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è"""
    processed_path = project_root / "data" / "processed" / "house_prices_processed.csv"

    if not processed_path.exists():
        print("   ‚úó –§–∞–π–ª –¥–∞–Ω–Ω—ã—Ö –Ω–µ –Ω–∞–π–¥–µ–Ω")
        return None, None

    df = pd.read_csv(processed_path)
    print(f"   ‚úÖ –î–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã: {df.shape}")

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ü–µ–ª–µ–≤—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é
    target_col = 'price_log' if 'price_log' in df.columns else 'price'

    if target_col not in df.columns:
        print(f"   ‚ö† –¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞, —Å–æ–∑–¥–∞–µ–º...")
        np.random.seed(42)
        df['price'] = np.random.lognormal(12, 0.4, len(df)).astype(int)
        target_col = 'price'

    # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏
    X = df.drop(columns=[target_col, 'id'], errors='ignore')

    # –£–¥–∞–ª—è–µ–º –∫–æ–ª–æ–Ω–∫–∏ —Å –ø–æ—Å—Ç–æ—è–Ω–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏
    for col in X.columns:
        if X[col].nunique() <= 1:
            X = X.drop(columns=[col])

    y = df[target_col]

    print(f"   üìä –ü—Ä–∏–∑–Ω–∞–∫–∏: {X.shape[1]}, –û–±—Ä–∞–∑—Ü—ã: {X.shape[0]}")
    return X, y


def train_linear_regression(X, y):
    """–û–±—É—á–∞–µ—Ç –º–æ–¥–µ–ª—å –ª–∏–Ω–µ–π–Ω–æ–π —Ä–µ–≥—Ä–µ—Å—Å–∏–∏"""
    print("\n2. –û–±—É—á–µ–Ω–∏–µ –ª–∏–Ω–µ–π–Ω–æ–π —Ä–µ–≥—Ä–µ—Å—Å–∏–∏...")

    from sklearn.model_selection import train_test_split
    from sklearn.linear_model import LinearRegression
    from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

    # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42
    )

    print(f"   –û–±—É—á–∞—é—â–∞—è –≤—ã–±–æ—Ä–∫–∞: {X_train.shape}")
    print(f"   –¢–µ—Å—Ç–æ–≤–∞—è –≤—ã–±–æ—Ä–∫–∞: {X_test.shape}")

    # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
    model = LinearRegression()
    model.fit(X_train, y_train)

    # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
    y_pred = model.predict(X_test)

    # –ú–µ—Ç—Ä–∏–∫–∏
    mae = mean_absolute_error(y_test, y_pred)
    mse = mean_squared_error(y_test, y_pred)
    rmse = np.sqrt(mse)
    r2 = r2_score(y_test, y_pred)

    print(f"\n   üìà –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ª–∏–Ω–µ–π–Ω–æ–π —Ä–µ–≥—Ä–µ—Å—Å–∏–∏:")
    print(f"   MAE:  {mae:.2f}")
    print(f"   MSE:  {mse:.2f}")
    print(f"   RMSE: {rmse:.2f}")
    print(f"   R¬≤:   {r2:.4f}")

    # –ï—Å–ª–∏ –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–ª–∏ –ª–æ–≥–∞—Ä–∏—Ñ–º, –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –º–µ—Ç—Ä–∏–∫–∏ –æ–±—Ä–∞—Ç–Ω–æ
    if 'price_log' in str(y.name):
        y_test_exp = np.expm1(y_test)
        y_pred_exp = np.expm1(y_pred)
        rmse_exp = np.sqrt(mean_squared_error(y_test_exp, y_pred_exp))
        print(f"   RMSE (–≤ –∏—Å—Ö–æ–¥–Ω—ã—Ö –µ–¥–∏–Ω–∏—Ü–∞—Ö): {rmse_exp:,.0f}")

    return model


def train_random_forest(X, y):
    """–û–±—É—á–∞–µ—Ç –º–æ–¥–µ–ª—å —Å–ª—É—á–∞–π–Ω–æ–≥–æ –ª–µ—Å–∞"""
    print("\n3. –û–±—É—á–µ–Ω–∏–µ —Å–ª—É—á–∞–π–Ω–æ–≥–æ –ª–µ—Å–∞...")

    from sklearn.ensemble import RandomForestRegressor
    from sklearn.model_selection import train_test_split, cross_val_score
    from sklearn.metrics import mean_squared_error, r2_score

    # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42
    )

    # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
    model = RandomForestRegressor(
        n_estimators=100,
        max_depth=10,
        random_state=42,
        n_jobs=-1
    )

    print("   –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏...")
    model.fit(X_train, y_train)

    # –ö—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è
    cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='r2')
    print(f"   R¬≤ (–∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è): {cv_scores.mean():.4f} ¬± {cv_scores.std():.4f}")

    # –û—Ü–µ–Ω–∫–∞ –Ω–∞ —Ç–µ—Å—Ç–µ
    y_pred = model.predict(X_test)
    r2 = r2_score(y_test, y_pred)
    rmse = np.sqrt(mean_squared_error(y_test, y_pred))

    print(f"   R¬≤ (—Ç–µ—Å—Ç): {r2:.4f}")
    print(f"   RMSE (—Ç–µ—Å—Ç): {rmse:.2f}")

    # –í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    if hasattr(model, 'feature_importances_'):
        feature_importance = pd.DataFrame({
            'feature': X.columns,
            'importance': model.feature_importances_
        }).sort_values('importance', ascending=False)

        print(f"\n   üèÜ –¢–æ–ø-5 –≤–∞–∂–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤:")
        for i, row in feature_importance.head(5).iterrows():
            print(f"   {row['feature']}: {row['importance']:.4f}")

    return model


def save_model(model, model_name):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –º–æ–¥–µ–ª—å –≤ —Ñ–∞–π–ª"""
    import joblib

    models_dir = project_root / "models"
    models_dir.mkdir(exist_ok=True)

    model_path = models_dir / f"{model_name}.pkl"
    joblib.dump(model, model_path)

    print(f"   ‚úÖ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {model_path}")
    return model_path


def save_metrics(metrics_dict, model_name):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ –º–æ–¥–µ–ª–∏"""
    import json

    models_dir = project_root / "models"
    models_dir.mkdir(exist_ok=True)

    metrics_path = models_dir / f"{model_name}_metrics.json"

    with open(metrics_path, 'w') as f:
        json.dump(metrics_dict, f, indent=2)

    print(f"   ‚úÖ –ú–µ—Ç—Ä–∏–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {metrics_path}")


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    print("=" * 60)
    print("–ó–ê–ü–£–°–ö –û–ë–£–ß–ï–ù–ò–Ø –ú–û–î–ï–õ–ï–ô")
    print("=" * 60)

    # 1. –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏ –ø–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ
    if not check_and_preprocess_data():
        print("\n‚úó –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–∏–ª–æ—Å—å —Å –æ—à–∏–±–∫–∞–º–∏")
        return

    # 2. –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
    X, y = load_and_prepare_data()
    if X is None or y is None:
        print("\n‚úó –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ")
        return

    print(f"\nüéØ –¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è: {y.name}")
    print(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π:")
    print(f"   –ú–∏–Ω: {y.min():.2f}")
    print(f"   –ú–∞–∫—Å: {y.max():.2f}")
    print(f"   –°—Ä–µ–¥–Ω–µ–µ: {y.mean():.2f}")
    print(f"   –ú–µ–¥–∏–∞–Ω–∞: {y.median():.2f}")

    # 3. –û–±—É—á–∞–µ–º –ª–∏–Ω–µ–π–Ω—É—é —Ä–µ–≥—Ä–µ—Å—Å–∏—é
    linear_model = train_linear_regression(X, y)
    save_model(linear_model, "linear_regression")

    # 4. –û–±—É—á–∞–µ–º —Å–ª—É—á–∞–π–Ω—ã–π –ª–µ—Å (–µ—Å–ª–∏ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö)
    if X.shape[0] > 100:
        rf_model = train_random_forest(X, y)
        save_model(rf_model, "random_forest")
    else:
        print("\n‚ö†Ô∏è  –°–ª–∏—à–∫–æ–º –º–∞–ª–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–ª—É—á–∞–π–Ω–æ–≥–æ –ª–µ—Å–∞, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")

    print("\n" + "=" * 60)
    print("‚úÖ –û–ë–£–ß–ï–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û –£–°–ü–ï–®–ù–û!")
    print("=" * 60)

    # –ü–æ–∫–∞–∑–∞—Ç—å –ø—É—Ç—å –∫ –º–æ–¥–µ–ª—è–º
    models_dir = project_root / "models"
    print(f"\nüìÅ –ú–æ–¥–µ–ª–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {models_dir}")
    print("–°–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤:")
    for file in models_dir.glob("*.pkl"):
        print(f"  - {file.name}")


if __name__ == "__main__":
    main()
'@ | Out-File -FilePath "scripts/run_training_fixed.py" -Encoding UTF8'